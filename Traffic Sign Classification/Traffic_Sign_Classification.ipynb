{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq7jLX8VXpab"
      },
      "outputs": [],
      "source": [
        "# dependencies\n",
        "!pip install opencv-contrib-python\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install scikit-image\n",
        "!pip install imutils\n",
        "!pip install matplotlib\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import gtsrb-german-traffic-sign dataset from kaggle\n",
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "\n",
        "#files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets list\n",
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
        "!mkdir gtsrb-german-traffic-sign\n",
        "!unzip gtsrb-german-traffic-sign.zip -d gtsrb-german-traffic-sign"
      ],
      "metadata": {
        "id": "tzZb-aZGFzbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' trafficsignnet.py '''\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "class TrafficSignNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\" and the channels dimension itself\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "    \n",
        "    # CONV => RELU => BN => POOL\n",
        "\t\tmodel.add(Conv2D(8, (5, 5), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "  \t# first set of (CONV => RELU => CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\t# second set of (CONV => RELU => CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  \n",
        "    # first set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(128))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\t\t# second set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(128))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(\"softmax\"))\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "metadata": {
        "id": "KWnSNBlJX7ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' train.py '''\n",
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "# import the necessary packages\n",
        "# import TrafficSignNet (trafficsignnet.py)\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "from skimage import transform\n",
        "from skimage import exposure\n",
        "from skimage import io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import os\n",
        "\n",
        "def load_split(basePath, csvPath):\n",
        "\t# initialize the list of data and labels\n",
        "\tdata = []\n",
        "\tlabels = []\n",
        "\t# load the contents of the CSV file, remove the first line (since\n",
        "\t# it contains the CSV header), and shuffle the rows (otherwise\n",
        "\t# all examples of a particular class will be in sequential order)\n",
        "\trows = open(csvPath).read().strip().split(\"\\n\")[1:]\n",
        "\trandom.shuffle(rows)\n",
        "\n",
        " \t# loop over the rows of the CSV file\n",
        "\tfor (i, row) in enumerate(rows):\n",
        "\t\t# check to see if we should show a status update\n",
        "\t\tif i > 0 and i % 1000 == 0:\n",
        "\t\t\tprint(\"[INFO] processed {} total images\".format(i))\n",
        "\t\t# split the row into components and then grab the class ID\n",
        "\t\t# and image path\n",
        "\t\t(label, imagePath) = row.strip().split(\",\")[-2:]\n",
        "\t\t# derive the full path to the image file and load it\n",
        "\t\timagePath = os.path.sep.join([basePath, imagePath])\n",
        "\t\timage = io.imread(imagePath)\n",
        "  \n",
        "  \t# resize the image to be 32x32 pixels, ignoring aspect ratio,\n",
        "\t\t# and then perform Contrast Limited Adaptive Histogram\n",
        "\t\t# Equalization (CLAHE)\n",
        "\t\timage = transform.resize(image, (32, 32))\n",
        "\t\timage = exposure.equalize_adapthist(image, clip_limit=0.1)\n",
        "\t\t# update the list of data and labels, respectively\n",
        "\t\tdata.append(image)\n",
        "\t\tlabels.append(int(label))\n",
        "\t# convert the data and labels to NumPy arrays\n",
        "\tdata = np.array(data)\n",
        "\tlabels = np.array(labels)\n",
        "\t# return a tuple of the data and labels\n",
        "\treturn (data, labels)\n",
        "\n",
        "datasetPath = '/content/gtsrb-german-traffic-sign'\n",
        "modelSavePath = '/content'\n",
        "plot = 'plot.png'\n",
        "\n",
        "# initialize the number of epochs to train for, base learning rate,\n",
        "# and batch size\n",
        "NUM_EPOCHS = 30\n",
        "INIT_LR = 1e-3\n",
        "BS = 64\n",
        "# load the label names\n",
        "labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
        "labelNames = [l.split(\",\")[1] for l in labelNames]\n",
        "\n",
        "# derive the path to the training and testing CSV files\n",
        "trainPath = os.path.sep.join([datasetPath, \"Train.csv\"])\n",
        "testPath = os.path.sep.join([datasetPath, \"Test.csv\"])\n",
        "# load the training and testing data\n",
        "print(\"[INFO] loading training and testing data...\")\n",
        "(trainX, trainY) = load_split(datasetPath, trainPath)\n",
        "(testX, testY) = load_split(datasetPath, testPath)\n",
        "# scale data to the range of [0, 1]\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        "# one-hot encode the training and testing labels\n",
        "numLabels = len(np.unique(trainY))\n",
        "trainY = to_categorical(trainY, numLabels)\n",
        "testY = to_categorical(testY, numLabels)\n",
        "# calculate the total number of images in each class and\n",
        "# initialize a dictionary to store the class weights\n",
        "classTotals = trainY.sum(axis=0)\n",
        "classWeight = dict()\n",
        "# loop over all classes and calculate the class weight\n",
        "for i in range(0, len(classTotals)):\n",
        "\tclassWeight[i] = classTotals.max() / classTotals[i]\n",
        "\n",
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=10,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.1,\n",
        "\theight_shift_range=0.1,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=False,\n",
        "\tvertical_flip=False,\n",
        "\tfill_mode=\"nearest\")\n",
        "# initialize the optimizer and compile the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / (NUM_EPOCHS * 0.5))\n",
        "model = TrafficSignNet.build(width=32, height=32, depth=3,\n",
        "\tclasses=numLabels)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=trainX.shape[0] // BS,\n",
        "\tepochs=NUM_EPOCHS,\n",
        "\tclass_weight=classWeight,\n",
        "\tverbose=1)\n",
        "\n",
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(testX, batch_size=BS)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=labelNames))\n",
        "# save the network to disk\n",
        "print(\"[INFO] serializing network to '{}'...\".format(modelSavePath))\n",
        "model.save(modelSavePath)\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = np.arange(0, NUM_EPOCHS)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(plot)"
      ],
      "metadata": {
        "id": "hYSk53Z0YMSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' predict.py '''\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.models import load_model\n",
        "from skimage import transform\n",
        "from skimage import exposure\n",
        "from skimage import io\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "modelPath = '/content/saved_model.pb'\n",
        "imagesPath = '/content/gtsrb-german-traffic-sign/Test'\n",
        "examplesPath = '/content/examples'\n",
        "\n",
        "# load the traffic sign recognizer model\n",
        "print(\"[INFO] loading model...\")\n",
        "model = load_model(modelPath)\n",
        "# load the label names\n",
        "labelNames = open(\"signnames.csv\").read().strip().split(\"\\n\")[1:]\n",
        "labelNames = [l.split(\",\")[1] for l in labelNames]\n",
        "# grab the paths to the input images, shuffle them, and grab a sample\n",
        "print(\"[INFO] predicting...\")\n",
        "imagePaths = list(paths.list_images(imagesPath))\n",
        "random.shuffle(imagePaths)\n",
        "imagePaths = imagePaths[:25]\n",
        "\n",
        "# loop over the image paths\n",
        "for (i, imagePath) in enumerate(imagePaths):\n",
        "\t# load the image, resize it to 32x32 pixels, and then apply\n",
        "\t# Contrast Limited Adaptive Histogram Equalization (CLAHE),\n",
        "\t# just like we did during training\n",
        "\timage = io.imread(imagePath)\n",
        "\timage = transform.resize(image, (32, 32))\n",
        "\timage = exposure.equalize_adapthist(image, clip_limit=0.1)\n",
        "\t# preprocess the image by scaling it to the range [0, 1]\n",
        "\timage = image.astype(\"float32\") / 255.0\n",
        "\timage = np.expand_dims(image, axis=0)\n",
        "\t# make predictions using the traffic sign recognizer CNN\n",
        "\tpreds = model.predict(image)\n",
        "\tj = preds.argmax(axis=1)[0]\n",
        "\tlabel = labelNames[j]\n",
        "\t# load the image using OpenCV, resize it, and draw the label\n",
        "\t# on it\n",
        "\timage = cv2.imread(imagePath)\n",
        "\timage = imutils.resize(image, width=128)\n",
        "\tcv2.putText(image, label, (5, 15), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "\t\t0.45, (0, 0, 255), 2)\n",
        "\t# save the image to disk\n",
        "\tp = os.path.sep.join([examplesPath, \"{}.png\".format(i)])\n",
        "\tcv2.imwrite(p, image)"
      ],
      "metadata": {
        "id": "954au4Tk3u97"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}